{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Cfv65rW2b7"
      },
      "source": [
        "### <font color='#4285f4'>Overview</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MpBBxscW2b7"
      },
      "source": [
        "Overview: Generates synthetic event data\n",
        "\n",
        "Author:\n",
        "* Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### <font color='#4285f4'>License</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### <font color='#4285f4'>Pip installs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# PIP Installs (if necessary)\n",
        "import sys\n",
        "\n",
        "# !{sys.executable} -m pip install REPLACE-ME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### <font color='#4285f4'>Initialize</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random\n",
        "\n",
        "import logging\n",
        "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "\n",
        "bigquery_location = \"${bigquery_non_multi_region}\"\n",
        "region = \"${region}\"\n",
        "location = \"${location}\"\n",
        "\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# Format the date and time as desired\n",
        "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### <font color='#4285f4'>Helper Methods</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import google.auth.transport.requests\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTYXm6hMW2b9"
      },
      "source": [
        "#### RetryCondition (for retrying LLM calls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXWlRM-fW2b9"
      },
      "outputs": [],
      "source": [
        "def RetryCondition(error):\n",
        "  error_string = str(error)\n",
        "  print(error_string)\n",
        "\n",
        "  retry_errors = [\n",
        "      \"RESOURCE_EXHAUSTED\",\n",
        "      \"No content in candidate\",\n",
        "      # Add more error messages here as needed\n",
        "  ]\n",
        "\n",
        "  for retry_error in retry_errors:\n",
        "    if retry_error in error_string:\n",
        "      print(\"Retrying...\")\n",
        "      return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOFTk6sj1YIV"
      },
      "source": [
        "#### Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHit3Hh-1ZAW"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
        "def GeminiLLM(prompt, model = \"gemini-2.5-flash\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 65536,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-2.0-flash\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(f\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(f\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        print(f\"GeminiLLM response: {response.content}\")\n",
        "        raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWXSCd5VCPjf"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
        "def GeminiLLM_VerifyImage(prompt, imageBase64, model = \"gemini-2.0-flash\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-2.0-flash\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "          { \"text\": prompt },\n",
        "          { \"inlineData\": {  \"mimeType\": \"image/png\", \"data\": f\"{imageBase64}\" } }\n",
        "        ]\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0UGKGtYoiy4"
      },
      "source": [
        "#### Imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vle77LwGomGF"
      },
      "outputs": [],
      "source": [
        "def ImageGen(prompt):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  model_version = \"imagen-4.0-generate-preview-06-06\" # Preview Access Model\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation\n",
        "  # url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/imagegeneration:predict\"\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/{model_version}:predict\"\n",
        "\n",
        "  payload = {\n",
        "    \"instances\": [\n",
        "      {\n",
        "        \"prompt\": prompt\n",
        "      }\n",
        "    ],\n",
        "    \"parameters\": {\n",
        "      \"sampleCount\": 1,\n",
        "      \"personGeneration\" : \"dont_allow\"  # change to allow_adult for people generation\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    response_json = json.loads(response.content)\n",
        "    # print(f\"Imagen3 response_json: {response_json}\")\n",
        "\n",
        "    if \"blocked\" in response_json:\n",
        "      print(f\"Blocked: {response_json['blocked']}\")\n",
        "\n",
        "    if \"predictions\" in response_json:\n",
        "      image_data = response_json[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "      image_data = base64.b64decode(image_data)\n",
        "      filename= str(uuid.uuid4()) + \".png\"\n",
        "      with open(filename, \"wb\") as f:\n",
        "        f.write(image_data)\n",
        "      print(f\"Image generated OK.\")\n",
        "      return filename\n",
        "    else:\n",
        "      raise RuntimeError(f\"No predictions in response: {response.content}\")\n",
        "  else:\n",
        "    error = f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8FaAkAFolpK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI-KJELZ1jgt"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnCwYvA1kZv"
      },
      "outputs": [],
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
        "      df_result = client.query(sql).to_dataframe()\n",
        "      return df_result\n",
        "  else:\n",
        "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Check on the progress by getting the job's updated state.\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "    )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    while query_job.state != \"DONE\":\n",
        "      time.sleep(2)\n",
        "      query_job = client.get_job(\n",
        "          query_job.job_id, location=query_job.location\n",
        "          )\n",
        "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    if query_job.error_result == None:\n",
        "      return True\n",
        "    else:\n",
        "      raise Exception(query_job.error_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYyeD08R1DRU"
      },
      "outputs": [],
      "source": [
        "def GetTableSchema(project_id, dataset_name, table_name):\n",
        "  import io\n",
        "  from google.cloud import bigquery\n",
        "\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  dataset_ref = client.dataset(dataset_name, project=project_id)\n",
        "  table_ref = dataset_ref.table(table_name)\n",
        "  table = client.get_table(table_ref)\n",
        "\n",
        "  f = io.StringIO(\"\")\n",
        "  client.schema_to_json(table.schema, f)\n",
        "  return f.getvalue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPz91mshqZBb"
      },
      "source": [
        "#### GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1T5-Rikqafm"
      },
      "outputs": [],
      "source": [
        "# This was generated by GenAI\n",
        "\n",
        "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
        "\n",
        "  Args:\n",
        "      local_file_path: The full path to the local file.\n",
        "      bucket_name: The name of the GCS bucket to upload to.\n",
        "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  import os\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # Ensure the file exists locally\n",
        "  if not os.path.exists(local_file_path):\n",
        "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
        "\n",
        "  # Create a storage client\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  # Get a reference to the bucket\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # Create a blob object with the desired destination path\n",
        "  blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "  # Upload the file from the local filesystem\n",
        "  content_type = \"\"\n",
        "  if local_file_path.endswith(\".html\"):\n",
        "    content_type = \"text/html; charset=utf-8\"\n",
        "\n",
        "  if local_file_path.endswith(\".json\"):\n",
        "    content_type = \"application/json; charset=utf-8\"\n",
        "\n",
        "  if content_type == \"\":\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "  else:\n",
        "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
        "\n",
        "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51M89g0Ejmz"
      },
      "source": [
        "### <font color='#4285f4'>MAIN CODE - Create Product Categories</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urKhNc2NYzFy"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "CREATE SCHEMA IF NOT EXISTS `agentic_beans_raw` OPTIONS(location = 'us-central1');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzGDL3SRg3nG"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "--DROP TABLE IF EXISTS `agentic_beans_raw.events`;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThaNTLFHbEm7"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `agentic_beans_raw.events`\n",
        "(\n",
        "    event_id            INT64      NOT NULL OPTIONS(description=\"The unique identifier and primary key for each event.\"),\n",
        "    event_title         STRING     NOT NULL OPTIONS(description=\"The public-facing title of the event.\"),\n",
        "    event_location      STRING     NOT NULL OPTIONS(description=\"The specific address or location of the event.\"),\n",
        "    event_description   STRING              OPTIONS(description=\"A detailed description of the event.\"),\n",
        "    event_start_date_time TIMESTAMP NOT NULL OPTIONS(description=\"The date and time when the event begins (UTC).\"),\n",
        "    event_end_date_time TIMESTAMP NOT NULL OPTIONS(description=\"The date and time when the event ends (UTC).\"),\n",
        "    age_range           STRING              OPTIONS(description=\"The recommended or required age range for event attendees (e.g., 'All Ages', '18+', '21+').\"),\n",
        "    event_venue         STRING              OPTIONS(description=\"The name of the venue where the event is held, if applicable.\"),\n",
        "    event_neighborhood  STRING              OPTIONS(description=\"The Manhattan neighborhood where the event takes place, based on the provided list.\")\n",
        ")\n",
        "CLUSTER BY event_id\n",
        "OPTIONS(\n",
        "    description=\"A table containing information about events where the coffee trucks will be present.\"\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffTfUSEVSGdT"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# OpenAPI 3.0 Schema for the Events data to be generated by the LLM\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"events_data\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"events_data\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"event_title\",\n",
        "          \"event_location\",\n",
        "          \"event_description\",\n",
        "          \"event_start_date_time\",\n",
        "          \"event_end_date_time\",\n",
        "          \"age_range\",\n",
        "          \"event_venue\",\n",
        "          \"event_neighborhood\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"event_title\": { \"type\": \"string\" },\n",
        "          \"event_location\": { \"type\": \"string\" },\n",
        "          \"event_description\": { \"type\": \"string\" },\n",
        "          \"event_start_date_time\": { \"type\": \"string\", \"format\": \"date-time\" },\n",
        "          \"event_end_date_time\": { \"type\": \"string\", \"format\": \"date-time\" },\n",
        "          \"age_range\": { \"type\": \"string\", \"enum\": [\"All Ages\", \"18+\", \"21+\", \"Family-Friendly\"] },\n",
        "          \"event_venue\": { \"type\": \"string\" },\n",
        "          \"event_neighborhood\": { \"type\": \"string\" }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# List of Manhattan neighborhoods as provided in [Item A]\n",
        "manhattan_neighborhoods = [\n",
        "    \"Marble Hill\", \"Central Harlem North\", \"Penn Station/Madison Sq West\", \"Roosevelt Island\",\n",
        "    \"Lincoln Square East\", \"Midtown Center\", \"East Village\", \"Upper West Side South\",\n",
        "    \"Manhattanville\", \"UN/Turtle Bay South\", \"Lenox Hill West\", \"Times Sq/Theatre District\",\n",
        "    \"Financial District South\", \"Clinton East\", \"Lincoln Square West\", \"Alphabet City\",\n",
        "    \"Lower East Side\", \"Chinatown\", \"Upper East Side South\", \"West Chelsea/Hudson Yards\",\n",
        "    \"Gramercy\", \"Lenox Hill East\", \"Clinton West\", \"Inwood Hill Park\", \"Bloomingdale\",\n",
        "    \"Greenwich Village South\", \"Upper East Side North\", \"Garment District\",\n",
        "    \"Greenwich Village North\", \"Hudson Sq\", \"Randalls Island\", \"Battery Park\",\n",
        "    \"Battery Park City\", \"Morningside Heights\", \"Washington Heights North\", \"Kips Bay\",\n",
        "    \"Murray Hill\", \"Seaport\", \"Yorkville West\", \"Two Bridges/Seward Park\",\n",
        "    \"TriBeCa/Civic Center\", \"Union Sq\", \"Midtown South\", \"Midtown North\", \"Flatiron\",\n",
        "    \"Sutton Place/Turtle Bay North\", \"World Trade Center\", \"SoHo\", \"East Chelsea\",\n",
        "    \"Manhattan Valley\", \"Governor's Island/Ellis Island/Liberty Island\",\n",
        "    \"Meatpacking/West Village West\", \"Upper West Side North\", \"East Harlem North\",\n",
        "    \"Hamilton Heights\", \"Little Italy/NoLiTa\", \"East Harlem South\",\n",
        "    \"Stuy Town/Peter Cooper Village\", \"Highbridge Park\", \"Central Park\", \"Midtown East\",\n",
        "    \"Washington Heights South\", \"Central Harlem\", \"West Village\", \"Yorkville East\",\n",
        "    \"Financial District North\", \"Inwood\"\n",
        "]\n",
        "\n",
        "# Get the maximum existing event_id to start from\n",
        "max_event_id_df = RunQuery(\"SELECT IFNULL(MAX(event_id) + 1, 1) as event_id FROM `agentic_beans_raw.events`\")\n",
        "max_event_id = int(max_event_id_df['event_id'][0])\n",
        "print(f\"Starting event_id: {max_event_id}\")\n",
        "\n",
        "event_start_date_df = RunQuery(\"SELECT CAST(CAST(IFNULL(MAX(event_end_date_time), '2020-01-01') AS DATE) AS STRING) as event_start_date FROM `agentic_beans_raw.events`\")\n",
        "event_start_date = str(event_start_date_df['event_start_date'][0])\n",
        "event_start_date = datetime.strptime(event_start_date, \"%Y-%m-%d\").date()\n",
        "print(f\"Starting event_start_date: {event_start_date}\")\n",
        "\n",
        "max_event_date = datetime.strptime('2027-01-01', \"%Y-%m-%d\").date()\n",
        "\n",
        "dataset_name = \"agentic_beans_raw\"\n",
        "table_name = \"events\"\n",
        "table_schema = GetTableSchema(project_id, dataset_name, table_name)\n",
        "event_response_raw = \"\"\n",
        "\n",
        "# Loop to generate and insert events\n",
        "event_id = max_event_id\n",
        "while event_start_date < max_event_date:\n",
        "  # do this twice for each day, we run out of output tokens\n",
        "  #for two_days in range(1,3,1):\n",
        "    print(f\"Generating events: {event_start_date} | {event_id}\")\n",
        "    success = False\n",
        "    while not success:\n",
        "      try:\n",
        "        prompt = f\"\"\"You are a database engineer and need to generate data for a table for the below schema.\n",
        "        The data is for events that occur in Manhattan, NYC.\n",
        "        I need you to generate approximately 25 realistic events per call.\n",
        "        The events should be typical events in NYC (events in parks, art festivals, events at bars, etc...)\n",
        "\n",
        "        Ensure the following constraints are met:\n",
        "        - The 'event_neighborhood' must be chosen from the provided list of Manhattan neighborhoods.\n",
        "        - The 'event_location' must be a specific, plausible street address or landmark within the chosen 'event_neighborhood'.\n",
        "        - The 'event_start_date_time' and 'event_end_date_time' must be valid UTC timestamps.\n",
        "        - The 'event_start_date_time' must be on the day: {event_start_date}\n",
        "        - 'event_end_date_time' must always be after 'event_start_date_time', with a duration typically between 2 to 8 hours.\n",
        "        - Make the 'event_title' and 'event_description' engaging and relevant.\n",
        "        - Vary the 'age_range' between 'All Ages', '18+', '21+', or 'Family-Friendly'.\n",
        "        - The 'event_venue' should be relevant to the location.\n",
        "\n",
        "        Here is the table schema:\n",
        "        <schema>\n",
        "        {json.dumps(table_schema, indent=2)}\n",
        "        </schema>\n",
        "\n",
        "        Here are the specific Manhattan neighborhoods for the events:\n",
        "        <event_neighborhoods>\n",
        "        {manhattan_neighborhoods}\n",
        "        </event_neighborhoods>\n",
        "        \"\"\"\n",
        "\n",
        "        # Use LLM to generate data\n",
        "        # print(f\"Prompt: {prompt}\") # Uncomment to see the full prompt\n",
        "        event_response_raw = GeminiLLM(prompt, response_schema=response_schema)\n",
        "\n",
        "        # Parse response\n",
        "        event_response = json.loads(event_response_raw)\n",
        "        #print(json.dumps(event_response, indent=2)) # Uncomment to see the LLM's raw response\n",
        "\n",
        "        if not event_response[\"events_data\"]:\n",
        "            print(\"LLM returned no events. Retrying...\")\n",
        "            continue\n",
        "\n",
        "        sql_values = []\n",
        "        for item in event_response[\"events_data\"]:\n",
        "\n",
        "          if item[\"event_title\"] is None:\n",
        "            event_title = \"\"\n",
        "          else:\n",
        "            event_title = item[\"event_title\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "\n",
        "          if item['event_location'] is None:\n",
        "            event_location = \"\"\n",
        "          else:\n",
        "            event_location = item[\"event_location\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "\n",
        "          if item[\"event_description\"] is None:\n",
        "            event_description = \"\"\n",
        "          else:\n",
        "            event_description = item[\"event_description\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "\n",
        "          event_start_date_time = item[\"event_start_date_time\"]\n",
        "          event_end_date_time = item[\"event_end_date_time\"]\n",
        "          age_range = item[\"age_range\"]\n",
        "          event_venue = item.get(\"event_venue\") # Use .get to handle potential null/missing\n",
        "          if event_venue is not None:\n",
        "            event_venue_sql = event_venue.replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "\n",
        "          if item[\"event_neighborhood\"] is None:\n",
        "            event_neighborhood = \"\"\n",
        "          else:\n",
        "            event_neighborhood = item[\"event_neighborhood\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "\n",
        "          event_start_date_time = event_start_date_time.replace(\"+00:00\",\"\")\n",
        "          event_end_date_time = event_end_date_time.replace(\"+00:00\",\"\")\n",
        "\n",
        "          sql_values.append(\n",
        "              f\"({event_id}, '{event_title}', '{event_location}', '{event_description}', \"\n",
        "              f\"PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%SZ', '{event_start_date_time}'), \"\n",
        "              f\"PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%SZ', '{event_end_date_time}'), \"\n",
        "              f\"'{age_range}', '{event_venue_sql}', '{event_neighborhood}')\"\n",
        "          )\n",
        "          event_id += 1\n",
        "\n",
        "        if sql_values:\n",
        "            sql = f\"\"\"INSERT INTO `{project_id}.{dataset_name}.{table_name}`\n",
        "                    (event_id, event_title, event_location, event_description, event_start_date_time, event_end_date_time, age_range, event_venue, event_neighborhood)\n",
        "                    VALUES \"\"\"\n",
        "            sql += \",\\n\".join(sql_values)\n",
        "            RunQuery(sql)\n",
        "\n",
        "        event_start_date = event_start_date + timedelta(days=1)\n",
        "\n",
        "        success = True\n",
        "      except Exception as error:\n",
        "        print(f\"event_response_raw: {event_response_raw}\")\n",
        "        print(f\"An error occurred during event generation/insertion: {error}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "JbOjdSP1kN9T",
        "kTYXm6hMW2b9",
        "s0UGKGtYoiy4",
        "iPz91mshqZBb",
        "ASQ2BPisXDA0"
      ],
      "name": "Agentic Beans - Data Generation: Events",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
