{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#4285f4'>Overview</font>"
      ],
      "metadata": {
        "id": "5uTya0Ip2m2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview: This notebook will generate Data for Order_header and order_detail table, code was generated using Gemini\n",
        "\n",
        "Cost:\n",
        "\n",
        "Approximate cost: $10\n",
        "\n",
        "Author:\n",
        "\n",
        "Navjot Singh\n",
        "\n",
        "Adam Paternostro"
      ],
      "metadata": {
        "id": "xJQe-I142plT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#4285f4'>License</font>"
      ],
      "metadata": {
        "id": "KtNRCN7x4fhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "sqeTuz-T4hcV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1758149631604,
          "user_tz": 420,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxVq-eZq8m_g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.cloud import bigquery\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import random\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI0xLxmm7HBa"
      },
      "source": [
        "# Create order_header Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIw82qhuHWy0"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE TABLE `agentic_beans_raw.order_header`(\n",
        "      order_header_id INTEGER OPTIONS(description=\"Unique identifier for each order header.\"),\n",
        "      order_header_timestamp TIMESTAMP OPTIONS(description=\"Timestamp when the order was placed.\"),\n",
        "      customer_id INTEGER OPTIONS(description=\"Identifier for the customer who placed the order.\"),\n",
        "      order_neighborhood STRING OPTIONS(description=\"Neighborhood where the order was placed or delivered, relevant for coffee truck operations.\")\n",
        "  )\n",
        "  OPTIONS(\n",
        "      description=\"Contains header information for orders placed at the coffee shop, potentially through coffee trucks.\"\n",
        "  );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwBLrlZFu5s9"
      },
      "source": [
        "# Create order_detail Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itFJzBFNr72l"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE TABLE `agentic_beans_raw.order_detail` (\n",
        "    order_detail_id INTEGER OPTIONS(description=\"Unique identifier for each line item in an order.\"),\n",
        "    order_header_id INTEGER OPTIONS(description=\"Foreign key linking to the order_header table, indicating which order this detail belongs to.\"),\n",
        "    truck_menu_id INTEGER OPTIONS(description=\"Identifier for the specific menu item ordered from the coffee truck's menu.\"),\n",
        "    order_quantity INTEGER OPTIONS(description=\"Quantity of the specific menu item ordered.\")\n",
        ")\n",
        "OPTIONS(\n",
        "    description=\"Contains detailed line items for each order, including the menu item and quantity, relevant for coffee shop and truck operations.\"\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYB5JNEO47wj"
      },
      "source": [
        "# Order Header prompt we used with Gemini to Generate Python code for Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa9noHsc46XA"
      },
      "outputs": [],
      "source": [
        "order_header_prompt = \"\"\"Give me python code to generate data for bigquery table order_header\n",
        "\n",
        "\n",
        "Order table should have following columns\n",
        "\n",
        "\n",
        "order_header_id - Primary Key with unique numeric value\n",
        "order_header_timestamp - time the order was placed\n",
        "customer_id - customer id of the customer who placed the order\n",
        "order_neighborhood - location where order was placed\n",
        "\n",
        "\n",
        "order_neighborhood should be one of the value from Select distinct weather_location from agentic_beans_raw.weather\n",
        "customer_id should be randomly selected from customer_id column of the table agentic_beans_raw.customer\n",
        "order_header_timestamp - it should be between Select max(observation_datetime), min(observation_datetime) from agentic_beans_raw.weather\n",
        "order_header_timestamp should be between 6 AM to 10 PM for each day\n",
        "No orders should be after 10 PM and before 6 AM\n",
        "I’m looking for certain patterns for these orders, specifically the number of orders within one hour window\n",
        "Number of orders within one hour window should depend on weather_description from agentic_beans_raw.weather table and events from agentic_beans_raw.events\n",
        "If order_location has ‘Clear’ weather_description in weather_location in agentic_beans_raw.weather table for that hour which you can match using observation_datetime column with order_timestamp columns, you can have more orders for that hour for that location\n",
        "Less random number of orders in case weather is Cloudy, Windy or Overcast\n",
        "Number of orders for each hour should be cosine wave\n",
        "If order_timestamp falls in between an event from events table using event_start_date_time\n",
        "And event_end_date_time for the order_location matches to event_neighborhood in events table, then increase the number of orders in orders table for that event duration\n",
        "\n",
        "Minimum orders within an hour window is 20 and maximum it could be 300\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRl3r9Yh52lX"
      },
      "source": [
        "# Order Detail prompt we used with Gemini to Generate Python code for Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz4DJZT057Hv"
      },
      "outputs": [],
      "source": [
        "order_detail_prompt = \"\"\"Give me python code to generate data for order_detail table\n",
        "\n",
        "\n",
        "\n",
        "order_detail table should have following columns\n",
        "order_detail_id - Primary key with unique numeric value\n",
        "order_header_id - a key chosen from agentic_beans_raw.order table\n",
        "truck_menu_id - truck_menu_id from agentic_beans_raw.truck_menu table\n",
        "order_quantity - either 1 or 2 randomly\n",
        "\n",
        "\n",
        "There could be 1 to 3 order details for one order_header_id\n",
        "\n",
        "There are 20 truck ids in the agentic_beans_raw.truck_menu table\n",
        "\n",
        "When choosing order_header_id from agentic_beans_raw.order_header table,  for a given hour in order_header_timestamp column,\n",
        "place truck only in one order_neighborhood, and choose the truck_menu_id for that truck,\n",
        "for example if on July 23rd 10 AM  truck id 3 is in Marble hill order_neighborhood,\n",
        "it should choose truck_menu_id from agentic_beans_raw.truck_menu table where truck_id=3 for all the orders in that hour,\n",
        "No other order_neighborhood should have menu Ids from truck_id=3\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p84rgDAV6iy0"
      },
      "source": [
        "**Once we got the Python Code from Gemini based on above prompts, we merged the code to generate data for both the tables, we are not going to regenerate the code again in this notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7cgZlM563UQ"
      },
      "source": [
        "# Define User Variables - Make Changes in this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1IBSMhz6-PC"
      },
      "outputs": [],
      "source": [
        "# --- 1. SCRIPT-WIDE CONFIGURATION ---\n",
        "\n",
        "# --- User-defined variables ---\n",
        "PROJECT_ID = \"Add_your_project_id\"  # <--- Change this to your GCP project ID\n",
        "DATASET_ID = \"agentic_beans_raw\"\n",
        "START_DATE_INPUT = \"2025-07-28\"  # <--- DEFINE the start date (inclusive)\n",
        "END_DATE_INPUT = \"2025-07-29\"    # <--- DEFINE the end date (exclusive)\n",
        "\n",
        "# --- Table IDs ---\n",
        "ORDER_HEADER_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.order_header\"\n",
        "ORDER_DETAIL_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.order_detail\"\n",
        "WEATHER_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.weather\"\n",
        "CUSTOMER_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.customer\"\n",
        "EVENTS_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.event\"\n",
        "TRUCK_MENU_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.truck_menu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SkqCBj77VoP"
      },
      "source": [
        "# BigQuery Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1TXZQtC7c7q"
      },
      "outputs": [],
      "source": [
        "# --- 2. BIGQUERY HELPER FUNCTIONS ---\n",
        "\n",
        "def get_max_id(client, table_id, column_name):\n",
        "    \"\"\"\n",
        "    Queries a table to find the maximum existing ID in a specified column.\n",
        "    Handles cases where the table is empty or doesn't exist.\n",
        "    \"\"\"\n",
        "    print(f\"Querying for MAX({column_name}) from {table_id}...\")\n",
        "    try:\n",
        "        query = f\"SELECT IFNULL(MAX({column_name}), 0) as max_id FROM `{table_id}`\"\n",
        "        results = client.query(query).result()\n",
        "        row = next(results)\n",
        "        max_id = row['max_id']\n",
        "        print(f\"Found max_id: {max_id}. New IDs will start from {max_id + 1}.\")\n",
        "        return max_id\n",
        "    except Exception as e:\n",
        "        print(f\"WARNING: Could not query max ID from {table_id}. Assuming table is empty. Reason: {e}\")\n",
        "        return 0\n",
        "\n",
        "def read_full_bigquery_table(client, table_id):\n",
        "    \"\"\"Reads an entire BigQuery table into a DataFrame.\"\"\"\n",
        "    print(f\"Reading full table from {table_id}...\")\n",
        "    try:\n",
        "        query = f\"SELECT * FROM `{table_id}`\"\n",
        "        df = client.query(query).to_dataframe()\n",
        "        print(f\"Successfully read {len(df)} rows from {table_id}.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to read {table_id}. Reason: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xuf6f-c7icD"
      },
      "source": [
        "# Order header generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws9KodNC7feu"
      },
      "outputs": [],
      "source": [
        "# --- 3. ORDER HEADER GENERATION LOGIC ---\n",
        "\n",
        "def generate_order_header_for_month(client, month_start, month_end, locations, customer_ids, weather_df, event_lookup, start_order_id):\n",
        "    \"\"\"Generates order_header data for a single month.\"\"\"\n",
        "    print(f\"\\n--- Generating Order Headers for period: {month_start.strftime('%Y-%m-%d')} to {month_end.strftime('%Y-%m-%d')} ---\")\n",
        "\n",
        "    generated_orders = []\n",
        "    order_id_counter = start_order_id\n",
        "    min_orders_per_hour = 20\n",
        "    max_orders_per_hour = 300\n",
        "\n",
        "    day_iterator = month_start.date()\n",
        "    while day_iterator <= month_end.date():\n",
        "        for hour in range(6, 22):  # 6 AM to 10 PM\n",
        "            hour_start_time = datetime.combine(day_iterator, datetime.min.time()).replace(hour=hour, tzinfo=timezone.utc)\n",
        "            if not (month_start <= hour_start_time < month_end):\n",
        "                continue\n",
        "\n",
        "            hour_end_time = hour_start_time + timedelta(hours=1)\n",
        "\n",
        "            for location in locations:\n",
        "                cosine_adjustment = (np.cos((hour - 14) * np.pi / 8) + 1) / 2\n",
        "                base_orders = int(min_orders_per_hour + (max_orders_per_hour - min_orders_per_hour) * cosine_adjustment)\n",
        "\n",
        "                try:\n",
        "                    weather_slice = weather_df.loc[hour_start_time:hour_end_time]\n",
        "                    if not weather_slice.empty:\n",
        "                        weather_now = weather_slice[weather_slice['weather_location'] == location]['weather_description'].iloc[0]\n",
        "                        if weather_now == 'Clear':\n",
        "                            base_orders *= 1.5\n",
        "                        elif weather_now in ['Cloudy', 'Windy', 'Overcast']:\n",
        "                            base_orders *= 0.7\n",
        "                except (IndexError, KeyError):\n",
        "                    pass\n",
        "\n",
        "                is_event = False\n",
        "                if location in event_lookup:\n",
        "                    for start, end in event_lookup[location]:\n",
        "                        if start < hour_end_time and end > hour_start_time:\n",
        "                            is_event = True\n",
        "                            break\n",
        "                if is_event:\n",
        "                    base_orders *= 4.0\n",
        "\n",
        "                num_orders = int(np.clip(base_orders, min_orders_per_hour, max_orders_per_hour))\n",
        "\n",
        "                for _ in range(num_orders):\n",
        "                    order_time = hour_start_time + timedelta(seconds=random.randint(0, 3599))\n",
        "                    if order_time < month_end:\n",
        "                        generated_orders.append({\n",
        "                            \"order_header_id\": order_id_counter,\n",
        "                            \"order_header_timestamp\": order_time,\n",
        "                            \"Customer_id\": random.choice(customer_ids),\n",
        "                            \"order_neighborhood\": location\n",
        "                        })\n",
        "                        order_id_counter += 1\n",
        "\n",
        "        day_iterator += timedelta(days=1)\n",
        "\n",
        "    return pd.DataFrame(generated_orders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olng3mYu7rkd"
      },
      "source": [
        "# Order Detail Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsWMYFx672QW"
      },
      "outputs": [],
      "source": [
        "# --- 4. ORDER DETAIL GENERATION LOGIC ---\n",
        "\n",
        "def generate_order_detail_data(orders_df, truck_menu_df, start_detail_id):\n",
        "    \"\"\"Generates order_detail data for a given DataFrame of orders.\"\"\"\n",
        "    print(f\"--- Generating Order Details for the month ---\")\n",
        "    if orders_df.empty:\n",
        "        print(\"No order headers to process, skipping detail generation.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    orders_df['order_header_timestamp'] = pd.to_datetime(orders_df['order_header_timestamp'])\n",
        "    orders_df['order_hour'] = orders_df['order_header_timestamp'].dt.floor('h')\n",
        "    location_hours = orders_df[['order_neighborhood', 'order_hour']].drop_duplicates()\n",
        "    all_truck_ids = truck_menu_df['truck_id'].unique()\n",
        "    np.random.seed(42)\n",
        "    location_hours['assigned_truck_id'] = np.random.choice(all_truck_ids, size=len(location_hours), replace=True)\n",
        "    orders_df = pd.merge(\n",
        "        orders_df,\n",
        "        location_hours,\n",
        "        on=['order_neighborhood', 'order_hour'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    num_orders = len(orders_df)\n",
        "    orders_df['num_details'] = np.random.randint(1, 4, size=num_orders)\n",
        "    order_detail_df = orders_df.loc[orders_df.index.repeat(orders_df['num_details'])].reset_index(drop=True)\n",
        "    menu_by_truck = truck_menu_df.groupby('truck_id')['truck_menu_id'].apply(list)\n",
        "    order_detail_df['possible_menus'] = order_detail_df['assigned_truck_id'].map(menu_by_truck)\n",
        "    order_detail_df['truck_menu_id'] = [\n",
        "        np.random.choice(menus) for menus in order_detail_df['possible_menus']\n",
        "    ]\n",
        "    order_detail_df['order_quantity'] = np.random.choice([1, 2], size=len(order_detail_df))\n",
        "\n",
        "    num_new_details = len(order_detail_df)\n",
        "    order_detail_df['order_detail_id'] = np.arange(start_detail_id, start_detail_id + num_new_details)\n",
        "\n",
        "    final_df = order_detail_df[[\n",
        "        'order_detail_id',\n",
        "        'order_header_id',\n",
        "        'truck_menu_id',\n",
        "        'order_quantity'\n",
        "    ]]\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUD4hNQe733L"
      },
      "source": [
        "# Generate Order Header and Order Detail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUsQzlgjiA_G"
      },
      "outputs": [],
      "source": [
        "# --- 5. MAIN EXECUTION BLOCK ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Initialization ---\n",
        "    try:\n",
        "        client = bigquery.Client(project=PROJECT_ID)\n",
        "        print(f\"BigQuery client initialized for project '{PROJECT_ID}'.\")\n",
        "    except Exception as e:\n",
        "        exit(f\"Failed to initialize BigQuery client. Error: {e}\")\n",
        "\n",
        "    try:\n",
        "        # These are correctly created as timezone-aware\n",
        "        start_date = pd.to_datetime(f'{START_DATE_INPUT} 00:00:00+0000', utc=True)\n",
        "        end_date = pd.to_datetime(f'{END_DATE_INPUT} 00:00:00+0000', utc=True)\n",
        "        monthly_periods = pd.period_range(start=start_date, end=end_date, freq='M')\n",
        "\n",
        "    except ValueError as e:\n",
        "        exit(f\"Invalid START_DATE_INPUT or END_DATE_INPUT format. Please use 'YYYY-MM-DD'. Error: {e}\")\n",
        "\n",
        "\n",
        "    # --- Pre-fetch and Pre-process Data (Done Once) ---\n",
        "    print(\"\\n--- Pre-fetching required data ---\")\n",
        "\n",
        "    locations_df = read_full_bigquery_table(client, WEATHER_TABLE_ID)[['weather_location']].drop_duplicates()\n",
        "    locations = locations_df['weather_location'].tolist()\n",
        "\n",
        "    customers_df = read_full_bigquery_table(client, CUSTOMER_TABLE_ID)\n",
        "    customer_ids = customers_df['customer_id'].tolist()\n",
        "\n",
        "    truck_menu_df = read_full_bigquery_table(client, TRUCK_MENU_TABLE_ID)\n",
        "\n",
        "    # Pre-process weather data\n",
        "    print(\"Pre-processing weather data...\")\n",
        "    weather_df = read_full_bigquery_table(client, WEATHER_TABLE_ID)\n",
        "    if not weather_df.empty:\n",
        "        dt_col = pd.to_datetime(weather_df['observation_datetime'])\n",
        "        if dt_col.dt.tz is None:\n",
        "            print(\"Weather 'observation_datetime' is timezone-naive. Localizing to UTC.\")\n",
        "            weather_df['observation_datetime'] = dt_col.dt.tz_localize('UTC')\n",
        "        else:\n",
        "            print(\"Weather 'observation_datetime' is already timezone-aware. Converting to UTC.\")\n",
        "            weather_df['observation_datetime'] = dt_col.dt.tz_convert('UTC')\n",
        "        weather_df = weather_df.set_index('observation_datetime').sort_index()\n",
        "\n",
        "    # Pre-process events data\n",
        "    print(\"Pre-processing events data...\")\n",
        "    events_df = read_full_bigquery_table(client, EVENTS_TABLE_ID)\n",
        "    event_lookup = defaultdict(list)\n",
        "    if not events_df.empty:\n",
        "        for col_name in ['event_start_date_time', 'event_end_date_time']:\n",
        "            dt_col = pd.to_datetime(events_df[col_name])\n",
        "            if dt_col.dt.tz is None:\n",
        "                print(f\"Events '{col_name}' is timezone-naive. Localizing to UTC.\")\n",
        "                events_df[col_name] = dt_col.dt.tz_localize('UTC')\n",
        "            else:\n",
        "                print(f\"Events '{col_name}' is already timezone-aware. Converting to UTC.\")\n",
        "                events_df[col_name] = dt_col.dt.tz_convert('UTC')\n",
        "        for _, row in events_df.iterrows():\n",
        "            event_lookup[row['event_neighborhood']].append(\n",
        "                (row['event_start_date_time'], row['event_end_date_time'])\n",
        "            )\n",
        "\n",
        "    if not locations or not customer_ids or truck_menu_df.empty:\n",
        "        exit(\"\\nHalting execution: Could not read required lookup data (locations, customers, or truck menu).\")\n",
        "\n",
        "\n",
        "    # --- Initialize ID counters from BigQuery ---\n",
        "    order_id_counter = get_max_id(client, ORDER_HEADER_TABLE_ID, 'order_header_id') + 1\n",
        "    detail_id_counter = get_max_id(client, ORDER_DETAIL_TABLE_ID, 'order_detail_id') + 1\n",
        "\n",
        "    total_headers_loaded = 0\n",
        "    total_details_loaded = 0\n",
        "\n",
        "    # --- Configure BigQuery Load Jobs (Done Once) ---\n",
        "    header_job_config = bigquery.LoadJobConfig(\n",
        "        schema=[\n",
        "            bigquery.SchemaField(\"order_header_id\", \"INTEGER\"),\n",
        "            bigquery.SchemaField(\"order_header_timestamp\", \"TIMESTAMP\"),\n",
        "            bigquery.SchemaField(\"Customer_id\", \"INTEGER\"),\n",
        "            bigquery.SchemaField(\"order_neighborhood\", \"STRING\"),\n",
        "        ],\n",
        "        write_disposition=\"WRITE_APPEND\",\n",
        "    )\n",
        "    detail_job_config = bigquery.LoadJobConfig(\n",
        "        schema=[\n",
        "            bigquery.SchemaField(\"order_detail_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "            bigquery.SchemaField(\"order_header_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "            bigquery.SchemaField(\"truck_menu_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "            bigquery.SchemaField(\"order_quantity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "        ],\n",
        "        write_disposition=\"WRITE_APPEND\"\n",
        "    )\n",
        "\n",
        "    # --- Main Monthly Processing Loop ---\n",
        "    for month_period in monthly_periods:\n",
        "        # --- MODIFIED BLOCK (START) ---\n",
        "        # FIX: Period.start_time and Period.end_time return NAIVE timestamps.\n",
        "        # We must localize them to UTC to make them AWARE, so they can be\n",
        "        # compared with the tz-aware start_date and end_date variables.\n",
        "        month_start_timestamp = month_period.start_time.tz_localize('UTC')\n",
        "        month_end_timestamp = month_period.end_time.tz_localize('UTC')\n",
        "        # --- MODIFIED BLOCK (END) ---\n",
        "\n",
        "        # Now all these variables are timezone-aware and can be compared safely.\n",
        "        current_month_start = max(month_start_timestamp, start_date)\n",
        "        current_month_end = min(month_end_timestamp, end_date)\n",
        "\n",
        "        print(f\"\\n{'='*60}\\nProcessing Period: {month_period} | From: {current_month_start.strftime('%Y-%m-%d %H:%M:%S %Z')} To: {current_month_end.strftime('%Y-%m-%d %H:%M:%S %Z')}\\n{'='*60}\")\n",
        "\n",
        "        # --- STEP 1: Generate and Load Order Header Data ---\n",
        "        order_header_df = generate_order_header_for_month(\n",
        "            client, current_month_start, current_month_end, locations, customer_ids, weather_df, event_lookup, order_id_counter\n",
        "        )\n",
        "\n",
        "        if not order_header_df.empty:\n",
        "            print(f\"Generated {len(order_header_df)} order headers.\")\n",
        "            print(f\"Uploading header batch to BigQuery table: {ORDER_HEADER_TABLE_ID}...\")\n",
        "            load_job = client.load_table_from_dataframe(\n",
        "                order_header_df, ORDER_HEADER_TABLE_ID, job_config=header_job_config\n",
        "            )\n",
        "            load_job.result()\n",
        "            headers_loaded = len(order_header_df)\n",
        "            total_headers_loaded += headers_loaded\n",
        "            order_id_counter += headers_loaded\n",
        "            print(f\"Successfully loaded {headers_loaded} header rows.\")\n",
        "\n",
        "            # --- STEP 2: Generate and Load Order Detail Data for the Same Month ---\n",
        "            try:\n",
        "                order_detail_df = generate_order_detail_data(\n",
        "                    order_header_df, truck_menu_df, start_detail_id=detail_id_counter\n",
        "                )\n",
        "\n",
        "                if not order_detail_df.empty:\n",
        "                    print(f\"Generated {len(order_detail_df)} order details.\")\n",
        "                    print(f\"Uploading detail batch to BigQuery table: {ORDER_DETAIL_TABLE_ID}...\")\n",
        "                    job = client.load_table_from_dataframe(\n",
        "                        order_detail_df, ORDER_DETAIL_TABLE_ID, job_config=detail_job_config\n",
        "                    )\n",
        "                    job.result()\n",
        "                    details_loaded = len(order_detail_df)\n",
        "                    total_details_loaded += details_loaded\n",
        "                    detail_id_counter += details_loaded\n",
        "                    print(f\"Successfully loaded {details_loaded} detail rows.\")\n",
        "\n",
        "            except KeyError as e:\n",
        "                print(f\"\\nCRITICAL ERROR: A KeyError occurred during detail generation: {e}.\")\n",
        "                print(\"This likely means a column name in the script does not match your BigQuery table.\")\n",
        "                print(\"Halting further processing.\")\n",
        "                break\n",
        "        else:\n",
        "            print(f\"No order headers were generated for the period {month_period}. Skipping to next period.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- SCRIPT COMPLETE ---\")\n",
        "    print(f\"Total Order Headers Loaded: {total_headers_loaded}\")\n",
        "    print(f\"Total Order Details Loaded: {total_details_loaded}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "Gen-Data-Generation-Order-Header-Details",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}