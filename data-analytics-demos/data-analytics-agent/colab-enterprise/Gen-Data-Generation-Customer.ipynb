{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Cfv65rW2b7"
      },
      "source": [
        "### <font color='#4285f4'>Overview</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MpBBxscW2b7"
      },
      "source": [
        "Overview: Generates synthetic customer data\n",
        "\n",
        "\n",
        "Cost:\n",
        "* Approximate cost: $1\n",
        "\n",
        "Author:\n",
        "* Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### <font color='#4285f4'>License</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### <font color='#4285f4'>Pip installs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# PIP Installs (if necessary)\n",
        "import sys\n",
        "\n",
        "# !{sys.executable} -m pip install REPLACE-ME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### <font color='#4285f4'>Initialize</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random\n",
        "\n",
        "import logging\n",
        "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "\n",
        "bigquery_location = \"${bigquery_non_multi_region}\"\n",
        "region = \"${region}\"\n",
        "location = \"${location}\"\n",
        "\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# Format the date and time as desired\n",
        "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### <font color='#4285f4'>Helper Methods</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import google.auth.transport.requests\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTYXm6hMW2b9"
      },
      "source": [
        "#### RetryCondition (for retrying LLM calls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXWlRM-fW2b9"
      },
      "outputs": [],
      "source": [
        "def RetryCondition(error):\n",
        "  error_string = str(error)\n",
        "  print(error_string)\n",
        "\n",
        "  retry_errors = [\n",
        "      \"RESOURCE_EXHAUSTED\",\n",
        "      \"No content in candidate\",\n",
        "      # Add more error messages here as needed\n",
        "  ]\n",
        "\n",
        "  for retry_error in retry_errors:\n",
        "    if retry_error in error_string:\n",
        "      print(\"Retrying...\")\n",
        "      return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOFTk6sj1YIV"
      },
      "source": [
        "#### Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHit3Hh-1ZAW"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
        "def GeminiLLM(prompt, model = \"gemini-2.5-flash\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 65536,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-2.0-flash\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(f\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(f\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWXSCd5VCPjf"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
        "def GeminiLLM_VerifyImage(prompt, imageBase64, model = \"gemini-2.0-flash\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-2.0-flash\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "          { \"text\": prompt },\n",
        "          { \"inlineData\": {  \"mimeType\": \"image/png\", \"data\": f\"{imageBase64}\" } }\n",
        "        ]\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(f\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(f\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(f\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(f\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0UGKGtYoiy4"
      },
      "source": [
        "#### Imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vle77LwGomGF"
      },
      "outputs": [],
      "source": [
        "def ImageGen(prompt):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  model_version = \"imagen-4.0-generate-preview-06-06\" # Preview Access Model\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation\n",
        "  # url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/imagegeneration:predict\"\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/{model_version}:predict\"\n",
        "\n",
        "  payload = {\n",
        "    \"instances\": [\n",
        "      {\n",
        "        \"prompt\": prompt\n",
        "      }\n",
        "    ],\n",
        "    \"parameters\": {\n",
        "      \"sampleCount\": 1,\n",
        "      \"personGeneration\" : \"dont_allow\"  # change to allow_adult for people generation\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    response_json = json.loads(response.content)\n",
        "    # print(f\"Imagen3 response_json: {response_json}\")\n",
        "\n",
        "    if \"blocked\" in response_json:\n",
        "      print(f\"Blocked: {response_json['blocked']}\")\n",
        "\n",
        "    if \"predictions\" in response_json:\n",
        "      image_data = response_json[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "      image_data = base64.b64decode(image_data)\n",
        "      filename= str(uuid.uuid4()) + \".png\"\n",
        "      with open(filename, \"wb\") as f:\n",
        "        f.write(image_data)\n",
        "      print(f\"Image generated OK.\")\n",
        "      return filename\n",
        "    else:\n",
        "      raise RuntimeError(f\"No predictions in response: {response.content}\")\n",
        "  else:\n",
        "    error = f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8FaAkAFolpK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI-KJELZ1jgt"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnCwYvA1kZv"
      },
      "outputs": [],
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
        "      df_result = client.query(sql).to_dataframe()\n",
        "      return df_result\n",
        "  else:\n",
        "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Check on the progress by getting the job's updated state.\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "    )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    while query_job.state != \"DONE\":\n",
        "      time.sleep(2)\n",
        "      query_job = client.get_job(\n",
        "          query_job.job_id, location=query_job.location\n",
        "          )\n",
        "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    if query_job.error_result == None:\n",
        "      return True\n",
        "    else:\n",
        "      raise Exception(query_job.error_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9caHWwBbyt-Z"
      },
      "outputs": [],
      "source": [
        "def GetTableSchema(project_id, dataset_name, table_name):\n",
        "  import io\n",
        "  from google.cloud import bigquery\n",
        "\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  dataset_ref = client.dataset(dataset_name, project=project_id)\n",
        "  table_ref = dataset_ref.table(table_name)\n",
        "  table = client.get_table(table_ref)\n",
        "\n",
        "  f = io.StringIO(\"\")\n",
        "  client.schema_to_json(table.schema, f)\n",
        "  return f.getvalue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPz91mshqZBb"
      },
      "source": [
        "#### GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1T5-Rikqafm"
      },
      "outputs": [],
      "source": [
        "# This was generated by GenAI\n",
        "\n",
        "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
        "\n",
        "  Args:\n",
        "      local_file_path: The full path to the local file.\n",
        "      bucket_name: The name of the GCS bucket to upload to.\n",
        "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  import os\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # Ensure the file exists locally\n",
        "  if not os.path.exists(local_file_path):\n",
        "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
        "\n",
        "  # Create a storage client\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  # Get a reference to the bucket\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # Create a blob object with the desired destination path\n",
        "  blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "  # Upload the file from the local filesystem\n",
        "  content_type = \"\"\n",
        "  if local_file_path.endswith(\".html\"):\n",
        "    content_type = \"text/html; charset=utf-8\"\n",
        "\n",
        "  if local_file_path.endswith(\".json\"):\n",
        "    content_type = \"application/json; charset=utf-8\"\n",
        "\n",
        "  if content_type == \"\":\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "  else:\n",
        "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
        "\n",
        "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51M89g0Ejmz"
      },
      "source": [
        "### <font color='#4285f4'>MAIN CODE - Create Product Categories</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urKhNc2NYzFy"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "CREATE SCHEMA IF NOT EXISTS `agentic_beans_raw` OPTIONS(location = 'us-central1');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzGDL3SRg3nG"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "--DROP TABLE IF EXISTS `agentic_beans_raw.customer`;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThaNTLFHbEm7"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `agentic_beans_raw.customer`\n",
        "(\n",
        "    customer_id             INTEGER NOT NULL OPTIONS(description=\"The unique identifier and primary key for each customer.\"),\n",
        "    customer_name           STRING  NOT NULL OPTIONS(description=\"The full name of the customer.\"),\n",
        "    customer_yob            INTEGER NOT NULL OPTIONS(description=\"The customer's year of birth, used for demographic analysis.\"),\n",
        "    customer_email          STRING  NOT NULL OPTIONS(description=\"The unique email address of the customer, used for marketing and receipts.\"),\n",
        "    customer_inception_date DATE    NOT NULL OPTIONS(description=\"The date of the customer's first transaction, marking their start date.\"),\n",
        "    country_code            STRING  NOT NULL OPTIONS(description=\"The two-letter ISO 3166-1 alpha-2 country code of the customer (e.g., 'US', 'CA', 'GB').\")\n",
        ")\n",
        "CLUSTER BY customer_id\n",
        "OPTIONS(\n",
        "    description=\"A table containing demographic and contact information for individual customers.\"\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDvK_0WgyzHW"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "\n",
        "yob_start = 1960\n",
        "yob_end = 2009"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffTfUSEVSGdT"
      },
      "outputs": [],
      "source": [
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_name\" : \"text\",\n",
        "#    \"customer_email\" : \"text\",\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_data\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_data\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"customer_name\",\n",
        "          \"customer_email\",\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"customer_name\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"customer_email\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "# Pick up where you left off\n",
        "# min_customer_id_df = RunQuery(\"SELECT IFNULL(MIN(customer_id),1) as customer_id FROM `agentic_beans_raw.customer`\")\n",
        "# min_customer_id = int(min_customer_id_df['customer_id'][0])\n",
        "# print(f\"min_customer_id: {min_customer_id}\")\n",
        "\n",
        "max_customer_id_df = RunQuery(\"SELECT IFNULL(MAX(customer_id) + 1,1) as customer_id FROM `agentic_beans_raw.customer`\")\n",
        "max_customer_id = int(max_customer_id_df['customer_id'][0])\n",
        "# print(f\"max_customer_id: {max_customer_id}\")\n",
        "\n",
        "dataset_name = \"agentic_beans_raw\"\n",
        "table_name = \"customer\"\n",
        "table_schema = GetTableSchema(project_id,dataset_name,table_name)\n",
        "\n",
        "other_countries = [\n",
        "    (\"Haiti\", \"HT\"),\n",
        "    (\"Colombia\", \"CO\"),\n",
        "    (\"Russia\", \"RU\"),\n",
        "    (\"Trinidad and Tobago\", \"TT\"),\n",
        "    (\"Guyana\", \"GY\"),\n",
        "    (\"Dominican Republic\", \"DO\"),\n",
        "    (\"Jamaica\", \"JM\"),\n",
        "    (\"Mexico\", \"MX\"),\n",
        "    (\"Ecuador\", \"EC\"),\n",
        "    (\"India\", \"IN\"),\n",
        "    (\"El Salvador\", \"SV\"),\n",
        "    (\"Bangladesh\", \"BD\"),\n",
        "    (\"Brazil\", \"BR\")\n",
        "]\n",
        "\n",
        "existing_customer_names_df = RunQuery(\"SELECT IFNULL(STRING_AGG(customer_name),'') as customer_names FROM `agentic_beans_raw.customer`\")\n",
        "existing_customer_names = str(existing_customer_names_df['customer_names'][0])\n",
        "#print(f\"existing_customer_names: {existing_customer_names}\")\n",
        "\n",
        "customer_id = max_customer_id\n",
        "while customer_id <= 10000:\n",
        "  print(f\"customer_id: {customer_id}\")\n",
        "  success = False\n",
        "  while not success:\n",
        "    try:\n",
        "      rand_int = random.randint(1, 100)\n",
        "      country = \"American\"\n",
        "      country_code = \"US\"\n",
        "\n",
        "      # Per Gemini\n",
        "      if rand_int <= 65:\n",
        "        # ~65% of the population is native-born.\n",
        "        country = \"American\"\n",
        "        country_code = \"US\"\n",
        "      elif rand_int <= 75:\n",
        "        # Dominican Republic is the largest immigrant group. (~10%)\n",
        "        country = \"Dominican\"\n",
        "        country_code = \"DO\"\n",
        "      elif rand_int <= 83:\n",
        "        country, country_code = random.choice(other_countries)\n",
        "      elif rand_int <= 88:\n",
        "        # Jamaica has a significant presence. (~5%)\n",
        "        country = \"Jamaican\"\n",
        "        country_code = \"JM\"\n",
        "      elif rand_int <= 92:\n",
        "        # Mexico is another major group. (~4%)\n",
        "        country = \"Mexican\"\n",
        "        country_code = \"MX\"\n",
        "      elif rand_int <= 95:\n",
        "        # India has a growing population in the city. (~3%)\n",
        "        country = \"Indian\"\n",
        "        country_code = \"IN\"\n",
        "      else:\n",
        "        # The remaining 5% is a mix of other prominent nationalities.\n",
        "        country, country_code = random.choice(other_countries)\n",
        "\n",
        "      prompt = f\"\"\"You are a database engineer and need to generate data for a table for the below schema.\n",
        "      I need you to generate a 100 customer names and email addresses based in the country {country}.\n",
        "      The customer email should be a random email address.\n",
        "      Read the description of each field for valid values.\n",
        "      Encourage unconventional ideas and fresh perspectives and inspires unique variations when creating the customer's name.\n",
        "\n",
        "      Here is the table schema:\n",
        "      <schema>\n",
        "      {table_schema}\n",
        "      </schema>\n",
        "\n",
        "      Here are the existing customer name, do not reuse any of these names:\n",
        "      <existing_customer_names>\n",
        "      {existing_customer_names}\n",
        "      </existing_customer_names>\n",
        "      \"\"\"\n",
        "\n",
        "      # Use LLM to generate data\n",
        "      # print(f\"Prompt: {prompt}\")\n",
        "      customer_response = GeminiLLM(prompt, response_schema=response_schema)\n",
        "\n",
        "      # Parse response (we know the JSON since we passed it to our LLM)\n",
        "      customer_response = json.loads(customer_response)\n",
        "      # print(json.dumps(customer_response, indent=2))\n",
        "\n",
        "      sql = f\"\"\"INSERT INTO `{project_id}.{dataset_name}.{table_name}`\n",
        "              (customer_id, customer_name, customer_yob, customer_email, customer_inception_date, country_code)\n",
        "              VALUES \"\"\"\n",
        "\n",
        "      for item in customer_response[\"customer_data\"]:\n",
        "        customer_name = item[\"customer_name\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "        customer_email = item[\"customer_email\"].replace(\"'\",\"\\\\'\").replace(\"\\n\", \" \")\n",
        "        customer_yob = random.randint(yob_start, yob_end)\n",
        "        start_date = date(2020, 1, 1)\n",
        "        end_date = date(2025, 12, 31)\n",
        "        total_days = (end_date - start_date).days\n",
        "        random_days = random.randint(0, total_days)\n",
        "        random_inception_date = start_date + timedelta(days=random_days)\n",
        "        customer_inception_date = random_inception_date.strftime('%Y-%m-%d')\n",
        "        existing_customer_names = existing_customer_names + f\",{customer_name}\"\n",
        "        sql = sql + f\"\"\"({customer_id}, '{customer_name}', {customer_yob}, '{customer_email}', '{customer_inception_date}', '{country_code}'),\"\"\"\n",
        "        customer_id += 1\n",
        "\n",
        "      sql = sql[:-1]\n",
        "      #print(f\"SQL: {sql}\")\n",
        "      RunQuery(sql)\n",
        "\n",
        "      success = True\n",
        "    except Exception as error:\n",
        "      print(f\"An error occurred: {error}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "JbOjdSP1kN9T",
        "kTYXm6hMW2b9",
        "bI-KJELZ1jgt",
        "iPz91mshqZBb",
        "ASQ2BPisXDA0"
      ],
      "name": "Agentic Beans - Data Generation: Customer",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
